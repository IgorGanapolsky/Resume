Igor Ganapolsky  
Coral Springs, FL  
iganapolsky@gmail.com | (201) 639-1534  
GitHub: https://github.com/IgorGanapolsky | LinkedIn: https://www.linkedin.com/in/igor-ganapolsky-859317343/  

2026-02-17

Hiring Team  
Runway  

Re: Member of Technical Staff, Inference (Greenhouse 4650230005)

I'm applying to Runway because inference is where product and systems engineering meet: low-latency, high-throughput, cost-sensitive workloads that still have to be reliable and debuggable at scale.

My background aligns well with inference platform work:

- Production AI systems: I ship LLM-backed features end-to-end on GCP/AWS with attention to reliability, rollout safety, and observability.
- Routing and cost/latency control: In my open-source trading system, I built a multi-model LLM gateway that routes via Tetrate Agent Router Service (TARS), supports provider fallbacks, and treats cost/latency constraints as first-class.
- Distributed-systems mindset: I approach infra by making failure modes measurable (logs/metrics/traces) so performance tuning and incident response are tractable.

I'd love to contribute to Runway's inference stack by improving performance, hardening reliability, and making the system easier to operate as load and model complexity grow.

Igor Ganapolsky

