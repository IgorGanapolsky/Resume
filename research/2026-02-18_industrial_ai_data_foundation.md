# Industrial AI "Trustworthy Data Foundation" Targeting (Deloitte + PTC Video)

Theme: industrial AI copilots only work when the underlying "systems of record" are connected and governed (PLM/CAD, ERP, MES, service parts, requirements). The opportunity is building the data + runtime layer that makes AI answers *verifiably grounded* and operationally safe.

## Role Angles To Target

- AI Systems Engineer (agent infrastructure, tool-using agents, evals, guardrails)
- Data Platform / Data Products Engineer (governed datasets, lineage, quality gates)
- Knowledge Graph / Enterprise Search Engineer (entity linking across PLM/ERP/MES)
- MLOps / LLMOps Engineer (deployment, observability, cost/latency control, eval harness)
- Solutions / Forward-Deployed Engineer (integrating copilots into real workflows)

## Keywords That Map To This Stack

- Digital thread, PLM, CAD, BOM, requirements, configuration management
- ERP/MES integration, supply chain analytics, service parts
- Data governance as code, data quality tests, lineage
- RAG, retrieval grounding, hallucination evaluation, red-teaming
- Tool-using agents, orchestration, multi-agent workflows
- Observability, tracing, cost/latency control, fallbacks

## Target Company Buckets

- Industrial platforms (systems of record):
  - PTC, Siemens, Dassault Systemes, Autodesk, SAP, Oracle
- Industrial automation + IoT:
  - Rockwell Automation, Honeywell, Schneider Electric, Bosch, GE (digital), Emerson
- Data/AI platforms with industrial GTM:
  - Databricks, Snowflake, Palantir, Confluent, Elastic
- Consulting / delivery at scale:
  - Deloitte, Accenture, Capgemini, Cognizant

## How To Position Igor's Experience For These Roles

- "Trust + correctness" framing: treat grounding, evals, and observability as first-class product requirements.
- Multi-system integration: tool-using agents + retrieval over authoritative sources (manuals, telemetry, structured data).
- Production hardening: CI/CD, rollback safety, and incident-driven iteration for AI features.
- AI infra emphasis: LLM routing, cost/latency constraints, fallbacks, and governance.

## Application Copy Snippets (Reusable)

- "I build AI systems that are grounded, observable, and cost-controlled. I treat hallucination risk as an engineering problem: data lineage, retrieval grounding, offline evals, and runtime guardrails."
- "In industrial contexts, I focus on connecting authoritative systems (PLM/ERP/telemetry) so agents can explain *why* an answer is correct and what source it came from."

